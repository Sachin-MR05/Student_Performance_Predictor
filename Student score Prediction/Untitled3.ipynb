{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model for the Student score Prediction\n",
    "\n",
    "This notebook demonstrates the complete machine learning pipeline for predicting student scores based on various features. We'll cover data loading, preprocessing, EDA, feature engineering, model training, evaluation, and conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd ,numpy as np, sklearn as sk,matplotlib.pyplot as plt,seaborn as sns,kagglehub\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Exploration\n",
    "\n",
    "This step involves downloading the dataset from Kaggle and loading it into a pandas DataFrame. We then perform initial exploration by displaying the first few rows to understand the structure and features of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"spscientist/students-performance-in-exams\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "# Load Dataset\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "files = os.listdir(path)\n",
    "\n",
    "print(\"Files in the dataset directory:\", files)\n",
    "\n",
    "\n",
    "\n",
    "csv_file_path = os.path.join(path, files[0])\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "In this step, we handle missing values by dropping rows with nulls. We also encode categorical variables using LabelEncoder to convert them into numerical format suitable for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "categorical_cols = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "\n",
    "for col in categorical_cols:\n",
    "\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "# Data Preprocessing\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df = df.dropna()\n",
    "X = df[['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']]\n",
    "\n",
    "y = df[['math score', 'reading score', 'writing score']]\n",
    "# StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA helps us understand the data distribution and relationships between variables. We use visualizations like histograms and correlation heatmaps to identify patterns and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA code here\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['math score'], kde=True)\n",
    "plt.title('Distribution of Math Scores')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature engineering involves creating new features or transforming existing ones to improve model performance. Here, we add polynomial features and create an average score feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "df['average score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1)\n",
    "\n",
    "print(\"Feature engineering completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "We train a machine learning model using the processed data. We evaluate its performance using metrics like MSE and R-squared, and visualize residuals to assess accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultiOutputRegressor(RandomForestRegressor(random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Visualization\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Key Findings\n",
    "\n",
    "This final step summarizes the project, highlighting key insights, model performance, and potential improvements for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "print(\"### Conclusion and Key Findings\")\n",
    "print(\"1. Data Overview: The dataset contains student performance data with features like gender, race/ethnicity, parental education, lunch type, and test preparation course.\")\n",
    "print(\"2. Preprocessing: Categorical variables were encoded, and features were scaled.\")\n",
    "print(\"3. EDA Insights: Visualizations showed distributions and correlations.\")\n",
    "print(\"4. Feature Engineering: Polynomial features and average score were added.\")\n",
    "print(\"5. Model Performance: The model achieved MSE of\", mse, \"and R-squared of\", r2)\n",
    "print(\"6. Key Findings: The model provides a baseline for prediction, but further improvements are possible.\")\n",
    "print(\"7. Future Improvements: Consider more advanced models or additional features.\")\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(model, 'student_score_model.pkl')\n",
    "print(\"Model saved as 'student_score_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
